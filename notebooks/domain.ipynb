{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f01589-f035-4d04-922a-c9c6495ad117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Tuple, Dict, List, Any\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler, Optimizer\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional.classification import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11ee339-dcd1-46f2-95d5-edca25fe5d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP_Block(nn.Module):\n",
    "    \"\"\"Building block for MLP-based models.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, hidden_size: int, activation: nn.Module, depth: int\n",
    "    ) -> None:\n",
    "        \"\"\"Initialization of the MLP block.\n",
    "\n",
    "        Args:\n",
    "            hidden_size: Number of neurons in the linear layer.\n",
    "            activation: Activation function.\n",
    "            depth: Number of MLP blocks (linear layer with activation).\n",
    "        \"\"\"\n",
    "        super(MLP_Block, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(depth):\n",
    "            linear = nn.Linear(hidden_size, hidden_size)\n",
    "            layers.append(linear)\n",
    "            layers.append(activation)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Propagates the input through the MLP block.\n",
    "\n",
    "        Args:\n",
    "            x: Input.\n",
    "\n",
    "        Returns:\n",
    "            Output of the network.\n",
    "        \"\"\"\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: Tuple[int],\n",
    "        output_shape: Tuple[int],\n",
    "        hidden_factor: int = 1,\n",
    "        depth: int = 1,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialization of the multi-layer perceptron.\n",
    "\n",
    "        Args:\n",
    "            input_shape: Shape of the input.\n",
    "            output_shape: Shape of the output.\n",
    "            hidden_factor: Factor for multiplying with input length to\n",
    "                determine the number of neurons in each hidden layer.\n",
    "                Defaults to 1.\n",
    "            depth: Number of hidden layers. Defaults to 1.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        input_len = int(np.prod(input_shape))\n",
    "        output_len = int(np.prod(output_shape))\n",
    "        hidden_size = int(input_len * hidden_factor)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [   \n",
    "                nn.Flatten(),\n",
    "                nn.Linear(input_len, hidden_size),  # Input layer\n",
    "                MLP_Block(hidden_size, nn.ReLU(), depth),\n",
    "                nn.Linear(hidden_size, output_len),  # Output layer\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Propagates the input through the MLP block.\n",
    "\n",
    "        Args:\n",
    "            x: Input.\n",
    "\n",
    "        Returns:\n",
    "            Output of the network.\n",
    "        \"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061442de-fc7e-4e6e-857d-5791aefaf74b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitClassificationModel(L.LightningModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        net: str,\n",
    "        lr: float,\n",
    "        num_classes: int,\n",
    "        criterion,\n",
    "        optimizer_class,\n",
    "        step_size,\n",
    "        scheduler_class,\n",
    "        ) -> None:\n",
    "        \"\"\"Initialization of the custom Lightning Module.\n",
    "\n",
    "        Args:\n",
    "            model: Neural network model name.\n",
    "            config: Neural network model and training config.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.num_classes = num_classes\n",
    "        self.criterion = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.step_size = step_size\n",
    "        self.scheduler_class = scheduler_class\n",
    "        self.net = net\n",
    "\n",
    "    def configure_optimizers(\n",
    "        self,\n",
    "    ) -> Tuple[Optimizer, lr_scheduler.LRScheduler]:\n",
    "        \"\"\"Configures the optimizer and scheduler based on the learning rate\n",
    "            and step size.\n",
    "\n",
    "        Returns:\n",
    "            Configured optimizer and scheduler.\n",
    "        \"\"\"\n",
    "        optimizer = self.optimizer_class(self.parameters(), lr=self.lr)\n",
    "        scheduler = self.scheduler_class(optimizer, self.step_size)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def infer_batch(\n",
    "        self, batch: Dict[str, dict]\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Propagate given batch through the Lightning Module.\n",
    "\n",
    "        Args:\n",
    "            batch: Batch containing the subjects.\n",
    "\n",
    "        Returns:\n",
    "            Model output and corresponding ground truth.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        y_hat = self.net(x)\n",
    "        return y_hat, y\n",
    "\n",
    "    def training_step(self, batch: Dict[str, dict], batch_idx: int) -> float:\n",
    "        \"\"\"Infer batch on training data, log metrics and retrieve loss.\n",
    "\n",
    "        Args:\n",
    "            batch: Batch containing the subjects.\n",
    "            batch_idx: Number displaying index of this batch.\n",
    "\n",
    "        Returns:\n",
    "            Calculated loss.\n",
    "        \"\"\"\n",
    "        y_hat, y = self.infer_batch(batch)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        y_hat, y = self.infer_batch(batch)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        acc =  multiclass_accuracy(y_hat, y, num_classes=self.num_classes)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('acc', acc, prog_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f2b40019-76fa-4dfe-88c2-d4057b844003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleFreqSpace(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, img):\n",
    "        return torch.fft.rfft2(img)\n",
    "\n",
    "\n",
    "class SimpleComplex2Vec(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.view_as_real(x)\n",
    "\n",
    "class BaseDataModule(L.LightningDataModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def train_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        \"\"\"Creates Dataloader for training phase.\n",
    "\n",
    "        Returns:\n",
    "            Dataloader for training phase.\n",
    "        \"\"\"\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_set, self.batch_size\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        \"\"\"Creates Dataloader for validation phase.\n",
    "\n",
    "        Returns:\n",
    "            Dataloader for validation phase.\n",
    "        \"\"\"\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_set, self.batch_size\n",
    "        )\n",
    "\n",
    "\n",
    "class ImageNetDataModule(BaseDataModule):\n",
    "    def __init__(self, data_dir: str, input_domain: str, batch_size: int = 32) -> None:\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.input_domain = input_domain\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self):\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        traindir = os.path.join(self.data_dir, 'train')\n",
    "        valdir = os.path.join(self.data_dir, 'val')\n",
    "\n",
    "        if self.input_domain == 'freq':\n",
    "            domain_transfrom = [SimpleFreqSpace(), SimpleComplex2Vec()]\n",
    "        else:\n",
    "            domain_transform = [lambda x: x]\n",
    "\n",
    "        self.train_set = ImageFolder(\n",
    "            traindir,\n",
    "            transforms.Compose(\n",
    "                [\n",
    "                    transforms.RandomResizedCrop(224),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                    *domain_transfrom,\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.val_set = ImageFolder(\n",
    "            valdir,\n",
    "            transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                    *domain_transfrom,\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "class MNISTDataModule(BaseDataModule):\n",
    "    \n",
    "    def __init__(self, input_domain: str, batch_size: int = 32) -> None:\n",
    "        super().__init__()\n",
    "        self.input_domain = input_domain\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        datasets.MNIST(\n",
    "            root=\"MNIST\", download=True, train=False)\n",
    "        datasets.MNIST(\n",
    "            root=\"MNIST\", download=True, train=False)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        tensor_transform = transforms.ToTensor()\n",
    "        \n",
    "        if self.input_domain == 'freq':\n",
    "            domain_transfrom = [SimpleFreqSpace(), SimpleComplex2Vec()]\n",
    "        else:\n",
    "            domain_transform = [lambda x: x]\n",
    "\n",
    "        self.test_set = datasets.MNIST(\n",
    "            root=\"MNIST\", download=True, train=False, transform= transforms.Compose([tensor_transform ]))\n",
    "        \n",
    "        # use 20% of training data for validation\n",
    "        train_set_size = int(len(train_set) * 0.8)\n",
    "        valid_set_size = len(train_set) - train_set_size\n",
    "        \n",
    "        self.train_set, self.val_set = torch.utils.data.random_split(\n",
    "            train_set, [train_set_size, valid_set_size], generator=seed)\n",
    "        \n",
    "        self.test_set = datasets.MNIST(\n",
    "            root=\"MNIST\", download=True, train=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fcb4bf2d-97c1-499d-bdec-99a27eff30a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNISTDataModule2(L.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        datasets.MNIST(self.data_dir, train=True, download=True)\n",
    "        datasets.MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\":\n",
    "            mnist_full = datasets.MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = torch.utils.data.random_split(\n",
    "                mnist_full, [55000, 5000], generator=torch.Generator().manual_seed(42)\n",
    "            )\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.mnist_test = datasets.MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "        if stage == \"predict\":\n",
    "            self.mnist_predict = datasets.MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=32)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.mnist_predict, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70b5f892-0e60-42e8-98b9-c809cb931f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import  defaultdict\n",
    "class FindSumPairs:\n",
    "\n",
    "    def __init__(self, nums1: List[int], nums2: List[int]):\n",
    "        self.dict1 = defaultdict(int)\n",
    "        for num in nums1:\n",
    "            self.dict1[num] += 1\n",
    "        self.dict2 = defaultdict(int)\n",
    "        for num in nums2:\n",
    "            self.dict2[num] += 1\n",
    "        self.nums2 = nums2\n",
    "\n",
    "    def add(self, index: int, val: int) -> None:\n",
    "        print(self.dict2)\n",
    "        self.dict2[self.nums2[index] + val] += 1\n",
    "        self.dict2[self.nums2[index]] -= 1 \n",
    "\n",
    "    def count(self, tot: int) -> int:\n",
    "        print(self.dict2)\n",
    "        ret = 0\n",
    "        for num, count in self.dict1.items():\n",
    "            ret += (count * self.dict2[tot - num])\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3e7de73f-7ebb-444d-9f7b-33fb333e7583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_set = datasets.MNIST(root=\"MNIST\", download=True, train=True, transform=transform)\n",
    "\n",
    "# use 20% of training data for validation\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "valid_set_size = len(train_set) - train_set_size\n",
    "\n",
    "# split the train set into two\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = torch.utils.data.random_split(train_set, [train_set_size, valid_set_size], generator=seed)\n",
    "\n",
    "test_set = datasets.MNIST(root=\"MNIST\", download=True, train=False, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3d5e9961-96b9-43bd-8caf-e92dc52d0d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = MLP([28, 28], [10])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "lr = 0.0001\n",
    "num_classes = 10\n",
    "step_size = 300\n",
    "scheduler_class = torch.optim.lr_scheduler.StepLR\n",
    "optimizer_class = torch.optim.Adam\n",
    "lit_model = LitClassificationModel(\n",
    "    net, lr, num_classes, criterion,\n",
    "    optimizer_class, step_size, scheduler_class\n",
    ")\n",
    "datamodule = MNISTDataModule2('pixel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4d6affa9-a35d-4a4e-8dff-48a8ca830016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to pixel/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                          | 0/9912422 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|██▏                                                                                                                                                                     | 131072/9912422 [00:00<00:08, 1118112.55it/s]\u001b[A\n",
      "  6%|██████████▌                                                                                                                                                             | 622592/9912422 [00:00<00:02, 3182846.36it/s]\u001b[A\n",
      " 10%|████████████████▊                                                                                                                                                        | 983040/9912422 [00:01<00:13, 680625.39it/s]\u001b[A\n",
      " 12%|████████████████████▌                                                                                                                                                   | 1212416/9912422 [00:01<00:14, 597346.66it/s]\u001b[A\n",
      " 14%|███████████████████████▎                                                                                                                                                | 1376256/9912422 [00:02<00:20, 425462.67it/s]\u001b[A\n",
      " 15%|████████████████████████▉                                                                                                                                               | 1474560/9912422 [00:02<00:18, 459202.64it/s]\u001b[A\n",
      " 16%|███████████████████████████▏                                                                                                                                            | 1605632/9912422 [00:02<00:16, 514401.54it/s]\u001b[A\n",
      " 17%|████████████████████████████▉                                                                                                                                           | 1703936/9912422 [00:03<00:19, 423285.16it/s]\u001b[A\n",
      " 18%|██████████████████████████████▌                                                                                                                                         | 1802240/9912422 [00:03<00:16, 482101.56it/s]\u001b[A\n",
      " 19%|████████████████████████████████▏                                                                                                                                       | 1900544/9912422 [00:03<00:21, 381084.85it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▎                                                                                                                                      | 1966080/9912422 [00:03<00:20, 382743.28it/s]\u001b[A\n",
      " 20%|██████████████████████████████████▍                                                                                                                                     | 2031616/9912422 [00:04<00:20, 384503.17it/s]\u001b[A\n",
      " 21%|████████████████████████████████████                                                                                                                                    | 2129920/9912422 [00:04<00:20, 386260.38it/s]\u001b[A\n",
      " 22%|█████████████████████████████████████▏                                                                                                                                  | 2195456/9912422 [00:04<00:19, 397532.08it/s]\u001b[A\n",
      " 23%|██████████████████████████████████████▎                                                                                                                                 | 2260992/9912422 [00:05<00:33, 227913.59it/s]\u001b[A\n",
      " 23%|███████████████████████████████████████▍                                                                                                                                | 2326528/9912422 [00:05<00:28, 263480.45it/s]\u001b[A\n",
      " 24%|█████████████████████████████████████████                                                                                                                               | 2424832/9912422 [00:05<00:21, 351506.02it/s]\u001b[A\n",
      " 25%|██████████████████████████████████████████▏                                                                                                                             | 2490368/9912422 [00:05<00:23, 310291.63it/s]\u001b[A\n",
      " 26%|███████████████████████████████████████████▎                                                                                                                            | 2555904/9912422 [00:05<00:25, 283961.80it/s]\u001b[A\n",
      " 26%|████████████████████████████████████████████▍                                                                                                                           | 2621440/9912422 [00:06<00:23, 311969.36it/s]\u001b[A\n",
      " 28%|██████████████████████████████████████████████▋                                                                                                                         | 2752512/9912422 [00:06<00:15, 460903.39it/s]\u001b[A\n",
      " 29%|████████████████████████████████████████████████▊                                                                                                                       | 2883584/9912422 [00:06<00:11, 612537.98it/s]\u001b[A\n",
      " 31%|███████████████████████████████████████████████████▋                                                                                                                    | 3047424/9912422 [00:06<00:11, 598428.35it/s]\u001b[A\n",
      " 32%|█████████████████████████████████████████████████████▎                                                                                                                  | 3145728/9912422 [00:06<00:11, 568706.39it/s]\u001b[A\n",
      " 33%|██████████████████████████████████████████████████████▉                                                                                                                 | 3244032/9912422 [00:07<00:15, 419767.03it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████                                                                                                                | 3309568/9912422 [00:07<00:17, 385242.27it/s]\u001b[A\n",
      " 34%|█████████████████████████████████████████████████████████▏                                                                                                              | 3375104/9912422 [00:07<00:20, 313093.93it/s]\u001b[A\n",
      " 35%|███████████████████████████████████████████████████████████▍                                                                                                            | 3506176/9912422 [00:07<00:14, 439016.27it/s]\u001b[A\n",
      " 37%|█████████████████████████████████████████████████████████████▋                                                                                                          | 3637248/9912422 [00:08<00:16, 383096.93it/s]\u001b[A\n",
      " 37%|██████████████████████████████████████████████████████████████▊                                                                                                         | 3702784/9912422 [00:08<00:16, 385029.49it/s]\u001b[A\n",
      " 38%|███████████████████████████████████████████████████████████████▊                                                                                                        | 3768320/9912422 [00:08<00:18, 327566.19it/s]\u001b[A\n",
      " 39%|████████████████████████████████████████████████████████████████▉                                                                                                       | 3833856/9912422 [00:08<00:16, 370846.18it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████████▋                                                                                                     | 3932160/9912422 [00:09<00:18, 324128.61it/s]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▊                                                                                                    | 3997696/9912422 [00:09<00:19, 302968.82it/s]\u001b[A\n",
      " 41%|█████████████████████████████████████████████████████████████████████▍                                                                                                  | 4096000/9912422 [00:09<00:14, 389095.65it/s]\u001b[A\n",
      " 42%|██████████████████████████████████████████████████████████████████████▌                                                                                                 | 4161536/9912422 [00:09<00:17, 336862.21it/s]\u001b[A\n",
      " 43%|███████████████████████████████████████████████████████████████████████▋                                                                                                | 4227072/9912422 [00:09<00:15, 358505.57it/s]\u001b[A\n",
      " 43%|████████████████████████████████████████████████████████████████████████▊                                                                                               | 4292608/9912422 [00:10<00:15, 367411.24it/s]\u001b[A\n",
      " 44%|██████████████████████████████████████████████████████████████████████████▍                                                                                             | 4390912/9912422 [00:10<00:13, 396016.77it/s]\u001b[A\n",
      " 45%|███████████████████████████████████████████████████████████████████████████▌                                                                                            | 4456448/9912422 [00:10<00:12, 425794.09it/s]\u001b[A\n",
      " 46%|████████████████████████████████████████████████████████████████████████████▋                                                                                           | 4521984/9912422 [00:10<00:13, 388346.35it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▊                                                                                          | 4587520/9912422 [00:10<00:14, 363537.26it/s]\u001b[A\n",
      " 47%|███████████████████████████████████████████████████████████████████████████████▍                                                                                        | 4685824/9912422 [00:11<00:11, 447593.55it/s]\u001b[A\n",
      " 48%|████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 4751360/9912422 [00:11<00:14, 346276.46it/s]\u001b[A\n",
      " 49%|██████████████████████████████████████████████████████████████████████████████████▏                                                                                     | 4849664/9912422 [00:11<00:15, 325375.44it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 4915200/9912422 [00:11<00:14, 336144.47it/s]\u001b[A\n",
      " 51%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                                  | 5046272/9912422 [00:12<00:13, 350157.83it/s]\u001b[A\n",
      " 52%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 5111808/9912422 [00:12<00:12, 381254.46it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▋                                                                                | 5177344/9912422 [00:12<00:11, 412134.47it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 5242880/9912422 [00:12<00:10, 433145.09it/s]\u001b[A\n",
      " 54%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 5308416/9912422 [00:12<00:13, 341755.61it/s]\u001b[A\n",
      " 55%|████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 5439488/9912422 [00:12<00:08, 502978.56it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                         | 5570560/9912422 [00:13<00:09, 466408.71it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                        | 5636096/9912422 [00:13<00:10, 427630.98it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 5701632/9912422 [00:13<00:11, 363977.22it/s]\u001b[A\n",
      " 59%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                     | 5799936/9912422 [00:13<00:09, 449023.49it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 5931008/9912422 [00:14<00:06, 578151.45it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 6029312/9912422 [00:14<00:08, 441744.51it/s]\u001b[A\n",
      " 61%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 6094848/9912422 [00:14<00:11, 342774.59it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                               | 6160384/9912422 [00:14<00:11, 314517.32it/s]\u001b[A\n",
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 6225920/9912422 [00:15<00:11, 317193.57it/s]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 6291456/9912422 [00:15<00:10, 358076.85it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 6356992/9912422 [00:15<00:08, 409206.06it/s]\u001b[A\n",
      " 65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 6422528/9912422 [00:15<00:10, 328361.75it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                          | 6488064/9912422 [00:15<00:09, 348486.15it/s]\u001b[A\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 6553600/9912422 [00:16<00:11, 289241.19it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 6619136/9912422 [00:16<00:09, 344683.83it/s]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 6684672/9912422 [00:16<00:08, 387955.41it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 6782976/9912422 [00:16<00:08, 354809.22it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 6848512/9912422 [00:16<00:08, 372841.46it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                  | 6914048/9912422 [00:17<00:10, 298267.47it/s]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 7045120/9912422 [00:17<00:06, 451112.18it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 7143424/9912422 [00:17<00:06, 404216.73it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 7208960/9912422 [00:17<00:06, 434303.75it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 7340032/9912422 [00:17<00:04, 590454.59it/s]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                          | 7438336/9912422 [00:18<00:06, 375760.00it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 7503872/9912422 [00:18<00:06, 377139.14it/s]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 7634944/9912422 [00:18<00:04, 521071.55it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 7766016/9912422 [00:18<00:03, 660403.58it/s]\u001b[A\n",
      " 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                  | 7864320/9912422 [00:18<00:04, 497328.39it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 7962624/9912422 [00:19<00:04, 399925.50it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 8028160/9912422 [00:19<00:04, 381925.78it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 8159232/9912422 [00:19<00:03, 517957.40it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 8257536/9912422 [00:20<00:04, 403134.98it/s]\u001b[A\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 8323072/9912422 [00:20<00:04, 330028.72it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                         | 8388608/9912422 [00:20<00:04, 353953.81it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 8519680/9912422 [00:20<00:02, 492384.44it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 8683520/9912422 [00:20<00:02, 596746.62it/s]\u001b[A\n",
      " 89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                   | 8781824/9912422 [00:21<00:02, 435156.34it/s]\u001b[A\n",
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 8847360/9912422 [00:21<00:03, 343148.74it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 8912896/9912422 [00:21<00:03, 329745.52it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 8978432/9912422 [00:22<00:03, 284979.61it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 9043968/9912422 [00:22<00:03, 270944.35it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 9076736/9912422 [00:22<00:03, 262779.52it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌            | 9175040/9912422 [00:22<00:02, 345380.50it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 9240576/9912422 [00:23<00:02, 244885.42it/s]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 9306112/9912422 [00:23<00:02, 251318.23it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 9371648/9912422 [00:23<00:02, 225380.76it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 9437184/9912422 [00:23<00:01, 271342.50it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 9502720/9912422 [00:24<00:02, 189394.22it/s]\u001b[A\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏     | 9568256/9912422 [00:24<00:01, 231696.79it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 9633792/9912422 [00:25<00:01, 176975.51it/s]\u001b[A\n",
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 9666560/9912422 [00:25<00:01, 192278.60it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉   | 9732096/9912422 [00:25<00:00, 236327.43it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 9797632/9912422 [00:25<00:00, 296394.63it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 9863168/9912422 [00:26<00:00, 204444.01it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:26<00:00, 378138.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting pixel/MNIST/raw/train-images-idx3-ubyte.gz to pixel/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to pixel/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                            | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 240154.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting pixel/MNIST/raw/train-labels-idx1-ubyte.gz to pixel/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to pixel/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|███▍                                                                                                                                                                      | 32768/1648877 [00:00<00:08, 193498.32it/s]\u001b[A\n",
      "  6%|██████████▏                                                                                                                                                               | 98304/1648877 [00:00<00:07, 199538.25it/s]\u001b[A\n",
      " 12%|████████████████████▏                                                                                                                                                    | 196608/1648877 [00:00<00:04, 313899.15it/s]\u001b[A\n",
      " 16%|██████████████████████████▊                                                                                                                                              | 262144/1648877 [00:01<00:06, 219799.08it/s]\u001b[A\n",
      " 18%|██████████████████████████████▏                                                                                                                                          | 294912/1648877 [00:01<00:06, 223765.31it/s]\u001b[A\n",
      " 22%|████████████████████████████████████▉                                                                                                                                    | 360448/1648877 [00:01<00:05, 252824.72it/s]\u001b[A\n",
      " 24%|████████████████████████████████████████▎                                                                                                                                | 393216/1648877 [00:01<00:06, 189255.26it/s]\u001b[A\n",
      " 26%|███████████████████████████████████████████▋                                                                                                                             | 425984/1648877 [00:01<00:06, 190525.56it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████████▍                                                                                                                      | 491520/1648877 [00:02<00:04, 231976.70it/s]\u001b[A\n",
      " 32%|█████████████████████████████████████████████████████▋                                                                                                                   | 524288/1648877 [00:02<00:04, 239176.45it/s]\u001b[A\n",
      " 36%|████████████████████████████████████████████████████████████▍                                                                                                            | 589824/1648877 [00:02<00:05, 208547.16it/s]\u001b[A\n",
      " 38%|███████████████████████████████████████████████████████████████▊                                                                                                         | 622592/1648877 [00:02<00:05, 196018.51it/s]\u001b[A\n",
      " 42%|██████████████████████████████████████████████████████████████████████▌                                                                                                  | 688128/1648877 [00:03<00:03, 241612.77it/s]\u001b[A\n",
      " 48%|████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 786432/1648877 [00:03<00:02, 343304.67it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 851968/1648877 [00:03<00:04, 194369.15it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 884736/1648877 [00:04<00:04, 184385.48it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                           | 917504/1648877 [00:04<00:03, 183962.11it/s]\u001b[A\n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 950272/1648877 [00:04<00:03, 183884.93it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 1015808/1648877 [00:04<00:02, 237987.63it/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                         | 1081344/1648877 [00:04<00:02, 274438.25it/s]\u001b[A\n",
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                      | 1114112/1648877 [00:04<00:01, 268435.72it/s]\u001b[A\n",
      " 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 1146880/1648877 [00:05<00:02, 247676.48it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 1212416/1648877 [00:05<00:02, 194306.50it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 1277952/1648877 [00:05<00:01, 237389.20it/s]\u001b[A\n",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 1376256/1648877 [00:05<00:00, 273996.08it/s]\u001b[A\n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 1409024/1648877 [00:06<00:00, 246785.09it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 1474560/1648877 [00:06<00:00, 286876.94it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 1507328/1648877 [00:06<00:00, 200150.25it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 1572864/1648877 [00:06<00:00, 247833.14it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:07<00:00, 227735.78it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting pixel/MNIST/raw/t10k-images-idx3-ubyte.gz to pixel/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to pixel/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 320834.80it/s]\u001b[A\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | net       | MLP              | 1.2 M \n",
      "-----------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.955     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting pixel/MNIST/raw/t10k-labels-idx1-ubyte.gz to pixel/MNIST/raw\n",
      "\n",
      "Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1719/1719 [00:34<00:00, 49.64it/s, v_num=46, train_loss=0.0136]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1719/1719 [00:34<00:00, 49.60it/s, v_num=46, train_loss=0.0136]\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=6)\n",
    "trainer.fit(model=lit_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ce6d81da-4bc2-40a8-a020-348de8cea8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:28<00:00, 355.74it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "           acc              0.9682000279426575\n",
      "        test_loss           0.34421759843826294\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.34421759843826294, 'acc': 0.9682000279426575}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=lit_model, dataloaders=DataLoader(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f22526d-7cc9-4932-a0b7-7b696cd7b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "domain",
   "language": "python",
   "name": "domain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
